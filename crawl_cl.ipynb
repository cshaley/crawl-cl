{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import crawler as cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General configuration steps\n",
    "# What cities do you want to search? Just the ones in your state? Or in your region?\n",
    "# Modifying state_list will automatically modify city_list\n",
    "states = cr.get_links_by_state()\n",
    "state_list = ['texas', 'arkansas', 'alabama', 'mississippi', 'new mexico', 'colorado', 'oklahoma', 'louisiana', 'kansas']\n",
    "city_list = []\n",
    "for state in state_list:\n",
    "    city_list += states[state]\n",
    "print city_list\n",
    "\n",
    "# Search strings and stop strings will filter your results\n",
    "# If an item's title does not contain any of the search strings, then that item will be dropped\n",
    "# If an item's title contains any of the stop strings, then that item will be dropped\n",
    "search_strings = ['2009', '2010', '2011', '2012', '2013', '2014', '2015']\n",
    "stop_strings = ['gti', 'chevrolet', 'chevy', 'ford', '3.0', 'touareg', 'nissan', 'gmc', 'chrysler',\n",
    "                'dodge', 'saturn', 'mercedes', 'honda', 'buick', 'toyota', 'jeep', 'lincoln',\n",
    "                'scion', 'yamaha', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is where we run the meat of the program\n",
    "\n",
    "ds = [] # List of dictionaries of data\n",
    "city_list = ['dallas'] # Make city_list short for testing\n",
    "\n",
    "# TODO:\n",
    "# cshaley: 2016/10/17\n",
    "# Restructure this to make it more linear.\n",
    "# i.e. Create a dataframe with all of the links to load for all of the cities,\n",
    "#      and then load all of those links.\n",
    "# Drop duplicate entries before loading them?\n",
    "\n",
    "# TODO\n",
    "# cshaley: 2016/10/18\n",
    "# Restructure the whole program - put in .py files and make it object oriented?\n",
    "\n",
    "for city in city_list:\n",
    "    # Create the query URL\n",
    "    url = \"https://{}.craigslist.org/search/cta?query=tdi\".format(city)\n",
    "    \n",
    "    # Get links to all of the items in the search results\n",
    "    tlst, hlst = cr.get_car_links(url)\n",
    "    \n",
    "    # If there were any results\n",
    "    if tlst and hlst:\n",
    "        # Create dataframe with craigslist items for sale as rows\n",
    "        df = pd.DataFrame(zip(tlst, hlst), columns=['Title', 'Link'])\n",
    "        \n",
    "        # Filter before loading individual URLS as loading each URL is slow.\n",
    "        # Filter out items that don't contain any search strings\n",
    "        df = df[df['Title'].str.lower().str.contains('|'.join(search_strings))]\n",
    "        # Filter out items that contain stop strings\n",
    "        df = df[~df['Title'].str.lower().str.contains('|'.join(stop_strings))]\n",
    "        \n",
    "        # Load each link and get the item attributes for each link.\n",
    "        # Create a dictionary and append it t\n",
    "        for lnk, title in zip(df['Link'].values, df['Title'].values):\n",
    "            d = cr.get_attrs(lnk)\n",
    "            d['Link'] = lnk\n",
    "            d['Title'] = title\n",
    "            ds.append(d)\n",
    "\n",
    "# Create a dataframe from the list of dictionaries\n",
    "car_data = pd.DataFrame(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print Number of results and clean data\n",
    "print(\"Raw car data number of results: {}\".format(len(car_data.index)))\n",
    "cleaned_car_data = car_data.drop_duplicates()\n",
    "print(\"Cleaned car data number of results: {}\".format(len(cleaned_car_data.index)))\n",
    "cleaned_car_data = cleaned_car_data[cleaned_car_data[u'title status: ']=='clean']\n",
    "print(\"Cleaned car data with clean title number of results: {}\".format(len(cleaned_car_data.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_car_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write data to disk - with a timestamp so you dont overwrite anything on accident\n",
    "now = re.sub('[ .:-]', '', str(datetime.datetime.now()))\n",
    "car_data.to_csv('raw_car_data_{}.csv'.format(now), index=False, encoding='utf-8')\n",
    "cleaned_car_data.to_csv('cleaned_car_data_{}.csv'.format(now), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read it for a sanity check\n",
    "read_car_data = pd.read_csv('raw_car_data_{}.csv'.format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_car_data.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
